{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lattice class -> intialization, algorithms on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class lattice:\n",
    "    \n",
    "    def __init__(self,L,p):\n",
    "        \n",
    "        self.L=L\n",
    "        self.p=p\n",
    "        self.lattice=[[-1]*(self.L+2)] #laticce sourronded by -1\n",
    "        #STUFF FOR BURNING METHOD:\n",
    "        self.reached_last_row=False\n",
    "        self.no_t_cell=False #there are no more cells with t number, burning method\n",
    "        #STUFF FO HOSHEN:\n",
    "        self.labels=[0,0]\n",
    "        self.labels.extend([x for x in range(2,self.L*self.L)]) #labels[i]=i kazdy na poczatku nie jest z nikim zwiazany oprocz siebie\n",
    "        self.counters=[0]*(self.L*self.L)\n",
    "        #CREATE LATTICE - RANDOM\n",
    "        for i in range(0,self.L):\n",
    "            lattice_row=[-1]\n",
    "            for j in range(0,self.L):\n",
    "                r=random.random()\n",
    "                if self.p>r:\n",
    "                    lattice_row.append(1)\n",
    "                else:\n",
    "                    lattice_row.append(0)\n",
    "                    \n",
    "            lattice_row.append(-1)\n",
    "            self.lattice.append(lattice_row)\n",
    "            \n",
    "        self.lattice.append([-1]*(self.L+2))\n",
    "        self.lattice_copy=copy.deepcopy(self.lattice)\n",
    "    \n",
    "    def set_lattice(self, table):\n",
    "        self.lattice=table\n",
    "    \n",
    "    def restart_lattice(self): #ONCE BUNRING METHOD PERFORM, RESTART LATTICE TO GET NORMAL TABLE AND PEROFORM HASHEN ON IT\n",
    "        #PARAMETERS RESTART:\n",
    "        self.reached_last_row=False #burning method\n",
    "        self.no_t_cell=False #there are no more cells with t number, burning method\n",
    "        self.labels=[0,0]\n",
    "        self.labels.extend([x for x in range(2,self.L*self.L)]) \n",
    "        self.counters=[0]*(self.L*self.L)\n",
    "        #LATTICE RESTART:\n",
    "        self.lattice=copy.deepcopy(self.lattice_copy)\n",
    "        \n",
    "    def new_random_lattice(self): #new random lattice\n",
    "        \n",
    "        self.lattice=[[-1]*(self.L+2)]\n",
    "        self.reached_last_row=False\n",
    "        self.no_t_cell=False \n",
    "        self.labels=[0,0]\n",
    "        self.labels.extend([x for x in range(2,self.L*self.L)]) \n",
    "        self.counters=[0]*(self.L*self.L)\n",
    "        \n",
    "        for i in range(0,self.L):\n",
    "            \n",
    "            lattice_row=[-1]\n",
    "            \n",
    "            for j in range(0,self.L):\n",
    "                r=random.random()\n",
    "                if self.p>r:\n",
    "                    lattice_row.append(1)\n",
    "                else:\n",
    "                    lattice_row.append(0)\n",
    "                    \n",
    "            lattice_row.append(-1)\n",
    "            self.lattice.append(lattice_row)\n",
    "            \n",
    "        self.lattice.append([-1]*(self.L+2))\n",
    "        self.lattice_copy=copy.deepcopy(self.lattice)\n",
    "    \n",
    "    def print_lattice(self):\n",
    "        for i in self.lattice:\n",
    "            print(i)\n",
    "\n",
    "#BURNING METHOD FUNCTIONS: \n",
    "    def check_neighbours(self,t,i,j): #burning method\n",
    "        \n",
    "        if self.lattice[i][j+1]==1:\n",
    "            self.lattice[i][j+1]=t+1\n",
    "            \n",
    "        if self.lattice[i][j-1]==1:\n",
    "            self.lattice[i][j-1]=t+1\n",
    "            \n",
    "        if self.lattice[i+1][j]==1:\n",
    "            self.lattice[i+1][j]=t+1\n",
    "            \n",
    "        if self.lattice[i-1][j]==1:\n",
    "            self.lattice[i-1][j]=t+1\n",
    "    \n",
    "    def iteration(self,t): #burning method\n",
    "        self.no_t_cell=True\n",
    "        for i in range(0,len(self.lattice)):\n",
    "            for j in range(0,len(self.lattice[0])):\n",
    "                if self.lattice[i][j]==t:\n",
    "                    self.no_t_cell=False\n",
    "                    self.check_neighbours(t,i,j)\n",
    "        #self.print_lattice()\n",
    "        \n",
    "    def reached_last_row_update(self): #burning method\n",
    "        self.reached_last_row=False\n",
    "        for i in self.lattice[-2]:\n",
    "            if i>1:\n",
    "                self.reached_last_row=True #dotarliśmy do ostatniego rzędu\n",
    "            \n",
    "    def burning_method(self): #shortest path finding\n",
    "        t=2\n",
    "        self.lattice[1]=[2 if i==1 else i for i in self.lattice[1]] #setting 2 in the first line\n",
    "        #self.print_lattice()\n",
    "        warunek=True\n",
    "        while self.reached_last_row==False and self.no_t_cell==False:\n",
    "            self.iteration(t)\n",
    "            self.reached_last_row_update()\n",
    "            t+=1\n",
    "        try:\n",
    "            return min([i for i in self.lattice[-2] if i>1])-1 #jest najkrotsza sciezka\n",
    "        except:\n",
    "            return 0\n",
    "        \n",
    "    def run_monte_burning_method(self):\n",
    "        self.new_random_lattice() #new random lattice\n",
    "        a=self.burning_method() #find shorest path\n",
    "        return a\n",
    "    \n",
    "#HASHEN ALGORITHM FUNCTIONS:\n",
    "    def find(self,x):\n",
    "        while self.labels[x] != x:\n",
    "            x = self.labels[x];\n",
    "        return x;\n",
    "    \n",
    "    def union(self,x,y): \n",
    "        if self.find(y)==self.find(x):\n",
    "            pass\n",
    "        ### nowe\n",
    "        else:\n",
    "            self.counters[self.find(y)]+=self.counters[self.find(x)]\n",
    "            self.counters[self.find(x)]=0\n",
    "        \n",
    "            self.labels[self.find(x)] = self.find(y);\n",
    "        \n",
    "    def hoshen_kopelman(self):\n",
    "        self.restart_lattice() #DELETE EFFECT OF BURNING ALGORITHM\n",
    "        k=1\n",
    "        for i, j in itertools.product(range(len(self.lattice)), range(len(self.lattice))):\n",
    "            top=self.lattice[i-1][j]\n",
    "            left=self.lattice[i][j-1]\n",
    "            if self.lattice[i][j]>0: #cell occupied\n",
    "                #case 1 top and left empty we create a new cluster label and set it to the current cell\n",
    "                if top<1 and left<1: \n",
    "                    k+=1\n",
    "                    self.lattice[i][j]=k\n",
    "                    self.counters[k]+=1\n",
    "                # case 2 top ocuupied left empty we set the cluster label of the occupied cell to the current cell\n",
    "                elif top>0 and left<1:\n",
    "                    k0=self.find(top)\n",
    "                    self.lattice[i][j]=k0\n",
    "                    self.counters[k0]+=1\n",
    "                # case 3 top empty left occupied\n",
    "                elif top<1 and left>0:\n",
    "                    k0=self.find(left)\n",
    "                    self.lattice[i][j]=k0\n",
    "                    self.counters[k0]+=1\n",
    "                #case 4 both occpuied same k0\n",
    "                elif top==left and top>0:\n",
    "                    k0=self.find(left)\n",
    "                    self.lattice[i][j] = k0#self.find(left)\n",
    "                    self.counters[k0]+=1\n",
    "                # case 5 both occupied different k0    \n",
    "                else:\n",
    "                    self.union(left,top)    \n",
    "                    k0=self.find(left)\n",
    "                    self.lattice[i][j] = k0#self.find(left)\n",
    "                    self.counters[k0]+=1\n",
    "                    \n",
    "        return [i for i in self.counters if i>0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if the code works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "najkrotsza sciezka 11\n",
      "clusters [18, 2, 51]\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "l=lattice(10,0.7)\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "sns.heatmap(l.lattice, square=True, ax=ax,cmap=\"Blues\")\n",
    "najkrotsza_sciezka=l.burning_method()\n",
    "print('najkrotsza sciezka',najkrotsza_sciezka)\n",
    "clusters=l.hoshen_kopelman()\n",
    "print('clusters',clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input():\n",
    "    input_data = open(\"perc_init.txt\",\"r\")\n",
    "    data=input_data.readlines()\n",
    "    L=data[0]\n",
    "    L=L.split(\" \")\n",
    "    L=L[1].split('\\n')\n",
    "    L=int(L[0])\n",
    "\n",
    "    T=data[1]\n",
    "    T=T.split(\" \")\n",
    "    T=T[1].split('\\n')\n",
    "    T=int(T[0])\n",
    "\n",
    "    p0=data[2]\n",
    "    p0=p0.split(\" \")\n",
    "    p0=p0[1].split('\\n')\n",
    "    p0=float(p0[0])\n",
    "\n",
    "    pk=data[3]\n",
    "    pk=pk.split(\" \")\n",
    "    pk=pk[1].split('\\n')\n",
    "    pk=float(pk[0])\n",
    "\n",
    "    dp=data[4]\n",
    "    dp=dp.split(\" \")\n",
    "    dp=dp[1].split('\\n')\n",
    "    dp=float(dp[0])\n",
    "    print('L',L,'T',T,'p0',p0,'pk',pk,'dp',dp)\n",
    "    return L,T,p0,pk,dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(T,p,L): #data for a specific probability, T trials\n",
    "    print(\"p\",p)\n",
    "    s_max=[]\n",
    "    s_ave=[]\n",
    "    path=[]\n",
    "    n_s_p_l=[]\n",
    "    l=lattice(L,p)\n",
    "    \n",
    "    for i in range(0,T):\n",
    "        #l=lattice(L,p)\n",
    "        l.new_random_lattice()\n",
    "        #print(l.print_lattice())\n",
    "        najkrotsza_sciezka=l.burning_method()\n",
    "        path.append(najkrotsza_sciezka)\n",
    "        clusters=l.hoshen_kopelman()\n",
    "        #print('clusters',clusters)\n",
    "        try: #WHAT IF CLUSTERS ARE EMPTY- LOW PROBABILITY OF 1 ASSIGNING THEN MAX WON'T WORK?\n",
    "            s_max.append(max(clusters))\n",
    "            s_ave.append(sum(clusters)/len(clusters))\n",
    "        except: #no clusters localized, clusters list is empty\n",
    "            s_max.append(0)\n",
    "            s_ave.append(0)\n",
    "        n_s_p_l+=clusters  #duza lista z rozkladami clustrow, tzn lista z wielkosciami clustrow w T powtorzen\n",
    "        #print('n_s_p_l',n_s_p_l)\n",
    "    \n",
    "    s_max_average=sum(s_max)/len(s_max)\n",
    "    s_average=sum(s_ave)/len(s_ave)\n",
    "    cluster_size,how_many_times=np.histogram(n_s_p_l,bins=2500)\n",
    "    average_shortest_path=sum(path)/len(path)\n",
    "    pflow=len([1 for i in path if i>0])/T\n",
    "    #print('n_s_p_l','p',p,n_s_p_l)\n",
    "    #print('resulting size, frequency',cluster_size,how_many_times)\n",
    "    return s_max_average, s_average, average_shortest_path, pflow, cluster_size, how_many_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file():\n",
    "    L,T,p0,pk,dp=read_input()\n",
    "    #print('T',T,'p0',p0,'pk',pk,'dp',dp,'L',L)\n",
    "    s_max_list=[]\n",
    "    s_ave_list=[]\n",
    "    path_list=[]\n",
    "    pflow_list=[]\n",
    "    ps=np.arange(p0,pk,dp)\n",
    "    \n",
    "    for p in range(int(p0*10000),int(pk*10000),int(dp*10000)):\n",
    "        \n",
    "        s_max_average, s_average, average_shortest_path, pflow, cluster_size, how_many_times = generate_data(T,p/10000,L)\n",
    "        s_max_list.append(s_max_average)\n",
    "        s_ave_list.append(s_average)\n",
    "        path_list.append(average_shortest_path)\n",
    "        pflow_list.append(pflow)\n",
    "        \n",
    "        #n(s,p,L) file generation for each probability\n",
    "        df2={'size':cluster_size, 'n(s,p,L)': how_many_times[:-1]}\n",
    "        df=pd.DataFrame(df2)\n",
    "        distribution_of_clusters_file='Dist_p'+str(p/10000)+'L'+str(L)+'T'+str(T)+'.txt'\n",
    "        np.savetxt('C:/Users/wojci/Documents/Studia/4 rok/Complex systems/Raport 1/generated_data_files/clusters_dist/'+\n",
    "                   distribution_of_clusters_file,\n",
    "                   df.values, fmt='%1.2f')\n",
    "   \n",
    "    df={'p':ps,'pflow':pflow_list,'d':path_list,'smax':s_max_list,'save':s_ave_list}\n",
    "    df=pd.DataFrame(df)\n",
    "    plik=\"Ave_L\"+str(L)+'T'+str(T)+'.txt'\n",
    "    np.savetxt('C:/Users/wojci/Documents/Studia/4 rok/Complex systems/Raport 1/generated_data_files/rest/'\n",
    "               +plik, df.values, fmt='%1.2f')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output results gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_file()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
